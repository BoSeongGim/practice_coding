{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60d5f11d-7e49-45a8-a8ae-0dea157b6bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 22:42:41.353022: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Introduction to Deep Learning with TensorFlow 2.0 (TensorFlow 2.0으로 배우는 딥러닝 입문)\n",
    "#lesson : [Section 3-Machine Learning Basic Theory_2] Implementation of Linear Regression algorithm using TensorFlow 2.0\n",
    "#강의명   : [섹션3-머신러닝 기초이론_2]TensorFlow 2.0을 이용한 선형 회귀(Linear Regression) 알고리즘 구현\n",
    "#https://www.inflearn.com/course/%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8#\n",
    "import tensorflow as tf\n",
    "\n",
    "#선형회귀 모델(Wx + b)을 위한 tf.Variable을 선언.\n",
    "W = tf.Variable(tf.random.normal(shape=[1]))\n",
    "b = tf.Variable(tf.random.normal(shape=[1]))\n",
    "# W, b : 파라미터이다.\n",
    "# shape : 차원을 뜻한다. 선형은 1개의 입력, 1개의 출력을 하기에 1차원(shape=[1])을 하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19d638f-81c7-43b3-a004-3728077bb0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process 1. Hypothetical setting definition\n",
    "#프로세스1.가설정의\n",
    "@tf.function\n",
    "def linear_model(x):\n",
    "  return W*x + b\n",
    "#-----(프로세스1.가설정의 END)-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "706d73be-d228-4157-8411-48d51d6ba7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process 2. Define loss function\n",
    "#프로세스2.손실함수 정의\n",
    "\n",
    "# MSE 손실함수 \\mean{(y' - y)^2}\n",
    "@tf.function\n",
    "def mse_loss(y_pred, y):\n",
    "  return tf.reduce_mean(tf.square(y_pred - y))\n",
    "#y_pred : linear_model이 예측한 prediction값을 받는 파라미터.\n",
    "#y : 실제 ground truth 값을 받는 파라미터.\n",
    "#tf.reduce_mean(tf.square(y_pred - y)) : mean-squared error의 수학적 공식을 코드로 표현함.\n",
    "#                                        두 개의 차이(y_pred - y)를 제곱(square)하여 평균(reduce_mean)을 취한다.\n",
    "#-----(프로세스2.손실함수 정의 END)-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7caa8d32-0486-478f-9143-e595a17956b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process 3. Optimizer definition & gradient descent process definition\n",
    "#프로세스3.옵티마이저 정의 & 그래디언트 디센트 과정정의\n",
    "\n",
    "#3.1.옵티마이저 정의(그라디언트 디센트 최적화를 위해 실시)\n",
    "optimizer = tf.optimizers.SGD(0.01)\n",
    "#tf.Optimizers API에 내장된 옵티마이저 클래스를 활용한다.\n",
    "#SGD : 미니배치 그래디언트 디센트를 수행해주는 기본 옵티마이저.(Adadelta등 다양한 클래스 옵티마이저들이 있다.)\n",
    "#      러닝메이트 알파를 0.01으로 설정한다.\n",
    "#참고URL https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "\n",
    "#3.2.최적화를 위한 function을 정의합니다.\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "  with tf.GradientTape() as tape:\n",
    "    y_pred = linear_model(x)\n",
    "    loss = mse_loss(y_pred, y)\n",
    "  gradients = tape.gradient(loss, [W, b])\n",
    "  optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "#y_pred = linear_model(x)   : 선형 모델에 기반한 예측결과 값.\n",
    "#loss = mse_loss(y_pred, y) : 실제값과 예측결과 값간의 오차를 계산한다.\n",
    "    \n",
    "#-----(#프로세스3.옵티마이저 정의 & 그래디언트 디센트 과정정의 END)------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38636e68-4001-4355-9529-e9b7a7c44b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.9966307  9.987604  10.984595  11.981587 ]\n"
     ]
    }
   ],
   "source": [
    "#프로세스4. 모델 학습\n",
    "#4.1.학습준비(입력값,출력값 준비)\n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [2, 4, 6, 8]\n",
    "\n",
    "#4.1.학습(경사하강법 1000번 실시)\n",
    "for i in range(1000):\n",
    "  train_step(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b00f935-9a01-4b94-895e-3577f9f07f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#프로세스5. 모델 평가실시.\n",
    "#5.1.평가준비(테스트용 입력데이터 준비)\n",
    "x_test = [3.5, 5, 5.5, 6]\n",
    "\n",
    "#5.2.평가 실시\n",
    "#선형회귀 모델이 데이터의 경향성(y=2x)을 잘 학습했는지 측정한다.\n",
    "#예상 참값 : [7, 10, 11, 12]\n",
    "print(linear_model(x_test).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "356cbb11-a4dc-4cce-bc2c-6df8226e0d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------[code only]--------------------------------------\n",
    "#import tensorflow as tf\n",
    "\n",
    "#W = tf.Variable(tf.random.normal(shape=[1]))\n",
    "#b = tf.Variable(tf.random.normal(shape=[1]))\n",
    "\n",
    "#@tf.function\n",
    "#def linear_model(x):\n",
    "#  return W*x + b\n",
    "\n",
    "#@tf.function\n",
    "#def mse_loss(y_pred, y):\n",
    "#  return tf.reduce_mean(tf.square(y_pred - y))\n",
    "\n",
    "#optimizer = tf.optimizers.SGD(0.01)\n",
    "\n",
    "#@tf.function\n",
    "#def train_step(x, y):\n",
    "#  with tf.GradientTape() as tape:\n",
    "#    y_pred = linear_model(x)\n",
    "#    loss = mse_loss(y_pred, y)\n",
    "#  gradients = tape.gradient(loss, [W, b])\n",
    "#  optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "\n",
    "#x_train = [1, 2, 3, 4]\n",
    "#y_train = [2, 4, 6, 8]\n",
    "\n",
    "#for i in range(1000):\n",
    "#  train_step(x_train, y_train)\n",
    "\n",
    "#x_test = [3.5, 5, 5.5, 6]\n",
    "#print(linear_model(x_test).numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
